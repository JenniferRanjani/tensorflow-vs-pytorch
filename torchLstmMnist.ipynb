{"cells":[{"cell_type":"code","execution_count":1,"id":"53f03b21","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53f03b21","executionInfo":{"status":"ok","timestamp":1661471452763,"user_tz":420,"elapsed":3654,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}},"outputId":"54e531aa-ddc3-4681-e1c6-1ef52f4feb12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"]}],"source":["!pip install torchinfo"]},{"cell_type":"code","source":["!nvidia-smi "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Ctk_BGSntEI","executionInfo":{"status":"ok","timestamp":1661471453037,"user_tz":420,"elapsed":281,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}},"outputId":"d398eb11-9d13-41a2-d7d9-5a8c460935d6"},"id":"8Ctk_BGSntEI","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Aug 25 23:50:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   65C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":3,"id":"db01d328","metadata":{"id":"db01d328","executionInfo":{"status":"ok","timestamp":1661471453990,"user_tz":420,"elapsed":955,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}}},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchinfo import summary"]},{"cell_type":"code","execution_count":4,"id":"4c8f3712","metadata":{"id":"4c8f3712","executionInfo":{"status":"ok","timestamp":1661471454405,"user_tz":420,"elapsed":7,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}}},"outputs":[],"source":["# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper parameters\n","num_epochs = 5\n","num_classes = 10\n","batch_size = 100\n","learning_rate = 0.001"]},{"cell_type":"code","execution_count":5,"id":"6aca5bd2","metadata":{"id":"6aca5bd2","executionInfo":{"status":"ok","timestamp":1661471454406,"user_tz":420,"elapsed":6,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}}},"outputs":[],"source":["# MNIST dataset\n","# pre-processor\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))])\n","\n","train_dataset = torchvision.datasets.MNIST(root='data/',\n","                                           train=True, \n","                                           transform=transform,\n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='data/',\n","                                          train=False, \n","                                          transform=transform)\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, \n","                                           shuffle=True, num_workers=2)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=batch_size, \n","                                          shuffle=False, num_workers=2)"]},{"cell_type":"code","execution_count":6,"id":"3e1561f2","metadata":{"id":"3e1561f2","executionInfo":{"status":"ok","timestamp":1661471457067,"user_tz":420,"elapsed":2666,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}}},"outputs":[],"source":["class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.layer1 = nn.LSTM(28, 128, 1, batch_first=True)\n","        self.layer2 = nn.LSTM(128, 64, 1, batch_first=True)\n","        self.fc1 = nn.Linear(7*8*32, 480)\n","        self.fc2   = nn.Linear(480, 120)\n","        self.fc3   = nn.Linear(120, num_classes)\n","\n","    def forward(self, x):\n","        h1 = torch.randn(1, x.size(0), 128).to(device)\n","        c1 = torch.randn(1, x.size(0), 128).to(device)\n","        out, (hn, cn) = self.layer1(x, (h1, c1))\n","\n","        h2 = torch.randn(1, out.size(0), 64).to(device)\n","        c2 = torch.randn(1, out.size(0), 64).to(device)\n","        out, (hn, cn) = self.layer2(out, (h2, c2))\n","\n","        out = out.reshape(out.size(0), -1)\n","        out = self.fc1(out)\n","        out = self.fc2(out)\n","        out = self.fc3(out)\n","        return out\n","\n","model = ConvNet(num_classes).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":7,"id":"5859ee67","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5859ee67","executionInfo":{"status":"ok","timestamp":1661471457317,"user_tz":420,"elapsed":253,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}},"outputId":"67b67020-29cb-4ceb-d754-b04ed26bab37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","ConvNet                                  [100, 10]                 --\n","├─LSTM: 1-1                              [100, 28, 128]            80,896\n","├─LSTM: 1-2                              [100, 28, 64]             49,664\n","├─Linear: 1-3                            [100, 480]                860,640\n","├─Linear: 1-4                            [100, 120]                57,720\n","├─Linear: 1-5                            [100, 10]                 1,210\n","==========================================================================================\n","Total params: 1,050,130\n","Trainable params: 1,050,130\n","Non-trainable params: 0\n","Total mult-adds (M): 457.52\n","==========================================================================================\n","Input size (MB): 0.31\n","Forward/backward pass size (MB): 4.79\n","Params size (MB): 4.20\n","Estimated Total Size (MB): 9.30\n","=========================================================================================="]},"metadata":{},"execution_count":7}],"source":["summary(model, input_size=(batch_size, 28, 28))"]},{"cell_type":"code","execution_count":8,"id":"ece27fe5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ece27fe5","executionInfo":{"status":"ok","timestamp":1661471520963,"user_tz":420,"elapsed":63648,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}},"outputId":"271964a3-bf8e-46a6-c3ee-43d5ea6df1b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Step [100/600], Loss: 0.4178\n","Epoch [1/5], Step [200/600], Loss: 0.2301\n","Epoch [1/5], Step [300/600], Loss: 0.1592\n","Epoch [1/5], Step [400/600], Loss: 0.3165\n","Epoch [1/5], Step [500/600], Loss: 0.0917\n","Epoch [1/5], Step [600/600], Loss: 0.0758\n","Epoch [2/5], Step [100/600], Loss: 0.1852\n","Epoch [2/5], Step [200/600], Loss: 0.0612\n","Epoch [2/5], Step [300/600], Loss: 0.0637\n","Epoch [2/5], Step [400/600], Loss: 0.1153\n","Epoch [2/5], Step [500/600], Loss: 0.0479\n","Epoch [2/5], Step [600/600], Loss: 0.1104\n","Epoch [3/5], Step [100/600], Loss: 0.0500\n","Epoch [3/5], Step [200/600], Loss: 0.0804\n","Epoch [3/5], Step [300/600], Loss: 0.0958\n","Epoch [3/5], Step [400/600], Loss: 0.0335\n","Epoch [3/5], Step [500/600], Loss: 0.0496\n","Epoch [3/5], Step [600/600], Loss: 0.1031\n","Epoch [4/5], Step [100/600], Loss: 0.0568\n","Epoch [4/5], Step [200/600], Loss: 0.0342\n","Epoch [4/5], Step [300/600], Loss: 0.0445\n","Epoch [4/5], Step [400/600], Loss: 0.0337\n","Epoch [4/5], Step [500/600], Loss: 0.0177\n","Epoch [4/5], Step [600/600], Loss: 0.0183\n","Epoch [5/5], Step [100/600], Loss: 0.0646\n","Epoch [5/5], Step [200/600], Loss: 0.0477\n","Epoch [5/5], Step [300/600], Loss: 0.0870\n","Epoch [5/5], Step [400/600], Loss: 0.0300\n","Epoch [5/5], Step [500/600], Loss: 0.0039\n","Epoch [5/5], Step [600/600], Loss: 0.0341\n"]}],"source":["\n","# Train the model\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.reshape(-1, 28, 28)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"]},{"cell_type":"code","execution_count":9,"id":"c0f9a34a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0f9a34a","executionInfo":{"status":"ok","timestamp":1661471522805,"user_tz":420,"elapsed":1846,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}},"outputId":"361a61a3-3bee-49bb-d972-7df05026b67d"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- 1.835646629333496 seconds ---\n"]}],"source":["# Test the model\n","import time\n","\n","\n","model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n","\n","start_time = time.time()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    pred =[]\n","    y_true = []\n","    for images, labels in test_loader:\n","        images = images.reshape(-1, 28, 28)\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        pred+=predicted.tolist()\n","        y_true+=labels.tolist()\n","\n","#     print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":10,"id":"90ae7bf7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90ae7bf7","executionInfo":{"status":"ok","timestamp":1661471523221,"user_tz":420,"elapsed":421,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}},"outputId":"1e12b97e-d7f4-4f32-e8d7-d40ef8ba98a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       980\n","           1       1.00      0.99      0.99      1135\n","           2       0.97      1.00      0.98      1032\n","           3       0.99      0.98      0.99      1010\n","           4       0.99      0.98      0.99       982\n","           5       0.99      0.99      0.99       892\n","           6       0.99      0.99      0.99       958\n","           7       0.99      0.98      0.98      1028\n","           8       0.99      0.98      0.99       974\n","           9       0.99      0.98      0.98      1009\n","\n","    accuracy                           0.99     10000\n","   macro avg       0.99      0.99      0.99     10000\n","weighted avg       0.99      0.99      0.99     10000\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","print(classification_report(y_true, pred))"]},{"cell_type":"code","execution_count":11,"id":"028f10f6","metadata":{"id":"028f10f6","executionInfo":{"status":"ok","timestamp":1661471523222,"user_tz":420,"elapsed":8,"user":{"displayName":"Jennifer Ranjani","userId":"01326273049975207174"}}},"outputs":[],"source":["# import torch.autograd.profiler as profiler\n","# with profiler.profile(with_stack=True, profile_memory=True) as prof:\n","#     out = model(images)\n","\n","# print(prof.key_averages(group_by_stack_n=5).table(sort_by='self_cpu_time_total', row_limit=5))"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"name":"torchLstmMnist.ipynb","provenance":[{"file_id":"1XM4W0JCKq7235PuetMuppZ9Sl4W0EfEd","timestamp":1661466676034}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}